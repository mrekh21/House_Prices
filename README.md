# სახლების ფასების პროგნოზი - House Prices: Advanced Regression Techniques

## კონკურსის მიმოხილვა:

ეს Kaggle-ის competition-ი მიზნად ისახავს სახლების საბოლოო ფასის ("SalePrice") პროგნოზირებას 79 მახასიათებლის გამოყენებით. 
კონკურსის მიზანია ისეთი მოდელის შექმნა, რომელიც მაქსიმალურად ზუსტად განსაზღვრავს საცხოვრებელი სახლის ღირებულებას.


## ჩემი მიდგომა პრობლემის გადასაჭრელად

### 1. მონაცემების ანალიზი და გაწმენდა
- სატრენინგო მონაცემების ანალიზი, არასაჭირო სვეტების ამოგდება
- გამოტოვებული მნიშვნელობების ანალიზი და შევსება
- კატეგორიული ცვლადების OneHotEncoding-ით გადაყვანა რიცხვითში


### 2. Feature Engineering
- არასაჭირო, დაბალი კორელაციის მქონე ცვლადების მოცილება
- 3 მეთოდით სხვადასხვა რაოდენობის ცვლადების ამორჩევა

### 3. ამორჩეული ცვლადებით საუკეთესო მოდელების შერჩევა და ტესტირება
- გამოყენებული ალგორითმები:
  - `LinearRegression`
  - `Ridge`
  - `Lasso`
  - `ElasticNet`
  - `DecisionTreeRegressor`
  - `RandomForestRegressor`
  - `XGBoostRegressor`
- GridSearchCV  ჰიპერპარამეტრების tuning-სთვის
- k-Fold-Cross-validation ვალიდაციისთვის
- MinMaxScaler და StandardScaler სკალირებისთვის

### 4. შეფასების მეტრიკები
- `R2 Score`
- `Mean Absolute Error (MAE)`
- `Mean Squared Error (MSE)`
- `Root Mean Squared Error (RMSE)`
- `Root Mean Squared Log Error`- Kaggle ამით აფასებს

### 5. მოდელის ლოგირება MLflow-ზე
- ექსპერიმენტის დასახელება: `Final_Pipeline`
- Run-ის სახელი: `RandomForest_with_preprocessing`
- მოდელის ატვირთვა Model Registry-ში
- მეტრიკების (MAE, MSE, RMSE, R2) და ჰიპერპარამეტრების ლოგირება

### 6. სატრენინგო მონაცემების ანალიზის ლოგირება MLflow-ზე
- ექსპერიმენტის დასახელება: `Train_Set_Analysis`
- Run-ის სახელი: `Train_Set_Analysis_Logging`
- Target ცვლადის, კატეგორიული და რიცხვითი ცვლადების განაწილებების, ასევე ცვეტების მიხედვით გამოტოვებული მონაცემების 
რაოდენობისა და პროცენტულობის ცხრილების ატვირთვა Artifacts-ში

### 7. Feature-ებისა და მათი შესაბამისი მოდელების შერჩევის 3 სხვადასხვა ვარიანტის ლოგირება MLflow-ზე:
- 1. 12 მახასიათებლის შერჩევა კორელაციის ფილტრით (threshold=0.5)
  - ექსპერიმენტის დასახელება: `Feature_Model_Selection_1`
  - Run-ის სახელი: `Corr_Threshold_0.5`
  - ამორჩეული feature-ების ლოგირება პარამეტრებში, ასევე ყველა მოდელის საუკეთესო ჰიპერპარამეტრების ლოგირება
  - მეტრიკებში საუკეთესო მოდელების საუკეთესო R2 score-ების ლოგირება
  - Artifacts-ში ამორჩეული მახასიათებლების კორელაციის ვიზუალიზაცია target-თან

- 2. 6 მახასიათებლის შერჩევა კორელაციის ფილტრით (threshold=0.6)
  - ექსპერიმენტის დასახელება: `Feature_Model_Selection_2`
  - Run-ის სახელი: `Corr_Threshold_0.6`
  - ამორჩეული feature-ების ლოგირება პარამეტრებში, ასევე ყველა მოდელის საუკეთესო ჰიპერპარამეტრების ლოგირება
  - მეტრიკებში საუკეთესო მოდელების საუკეთესო R2 score-ების ლოგირება
  - Artifacts-ში ამორჩეული მახასიათებლების კორელაციის ვიზუალიზაცია target-თან

- 3. 10 მახასიათებლის შერჩევა კორელაციის ფილტრით (threshold=0.4) და RFE-ით
  - ექსპერიმენტის დასახელება: `Feature_Model_Selection_3`
  - Run-ის სახელი: `Corr_Threshold_0.4_with_RFE`
  - ამორჩეული feature-ების ლოგირება პარამეტრებში, ასევე ყველა მოდელის საუკეთესო ჰიპერპარამეტრების ლოგირება
  - მეტრიკებში საუკეთესო მოდელების საუკეთესო R2 score-ების ლოგირება
  - Artifacts-ში კორელაციის ფილტრით ამორჩეული 22 მახასიათებლის კორელაციის ვიზუალიზაცია target-თან და 
  შემდეგ 22-დან RFE-ით ამორჩეული 10 მახასიათებლის კორელაციის ვიზუალიზაცია target-თან, ასევე Top 15 ცვლადი RFE-ით



## რეპოზიტორიის სტრუქტურა
- `model_experiment.ipynb`: სატრენინგო მონაცემების ანალიზი, Cleaning, Feature Engineering, Feature Selection, Training, 
საბოლოო pipeline თავისი preprocessing კლასით და MLflow-ზე დალოგვები.
- `model_inference.ipynb`: მოდელის და-load-ება, ტესტ სეტზე პროგნოზი და csv ფაილად შენახვა submission-სთვის.
- `README.md`: ახლა რასაც კითხულობთ, ეგ.

## Feature Engineering
- `Id` სვეტი თავიდანვე მოვაშორე, რადგან ტრენინგში არ გვჭირდება.
- Nan მნიშვნელობების ანალიზი: 
  - 1453 (99.52%) nan value გვქონდა კატეგორიულ `PoolQC`-ში, რაც არის აუზის ხარისხი. თუ ვნახავთ მის შესაბამის numerical სვეტს, 
  "PoolArea", რომელიც არის აუზის ფართობი, მისი 1453 მნიშვნელობა არის 0, რაც იმას ნიშნავს, რომ სახლების უმეტესობას აუზი არ აქვს, 
  შესაბამისად "PoolQC" ანუ აუზის ხარისხის კატეგორიული მნიშვნელობები გამოტოვებულია.
  - 1406 (96.3%) nan value გვქონდა კატეგორიულ სვეტში `MiscFeature` რომელიც არის Miscellaneous feature not covered in other categories, 
  რომლის შესაბამისი numerical ცვლადის "MiscVal"-ის ანუ $Value of miscellaneous feature-ის 1400-ზე მეტი მნიშვნელობა ასევე არის 0, რაც იმას ნიშნავს, 
  რომ ეს მახასიათებელი სახლების უმეტესობას არ გააჩნია.
  - 1369 (93.77%) nan value გვქონდა კატეგორიულ სვეტში `Alley`, რაც არის Type of alley access, რაც სავარაუდოდ სახლების უმეტესობას არ აქვს.
  - 1179 (80.75%) nan value გვქონდა კატეგორიულ სვეტში `Fence`, რომელიც არის ღობის ხარისხი, ამიტომ ამდენი გამოტოვებული მონაცემის არსებობა სავარაუდოდ 
  ნიშნავს, რომ სახლების უმეტესობას ღობე საერთოდ არ აქვს.
  - 872 (59.73%) nan value გვქონდა კატეგორიულ სვეტში `MasVnrType`, რომელიც არის Masonry veneer type, რომლის შესაბამისი numerical სვეტია "MasVnrArea", 
  რომლის 800-ზე მეტი მნიშვნელობა არის 0, რაც იმას ნიშნავს, რომ სახლების ნახევარზე მეტს Masonry veneer საერთოდ არ გააჩნია, შესაბამისად მისი ტიპის აღმნიშვნელი 
  კატეგორიული ცვლადის მნიშვნელობები გამოტოვებულია.
  - 690 (47.26%) nan value გვქონდა კატეგორიულ სვეტში `FireplaceQu`, რომელიც არის Fireplace quality. მისი შესაბამისი numerical ცვლადია "Fireplaces" 
  ანუ Number of fireplaces, რომლის 690 მნიშვნელობა არის 0, რაც იმას ნიშნავს, რომ სახლების ამ რაოდენობას არ გააჩნია ბუხრები, შესაბამისად მისი ხარისხის აღმნიშვნელი 
  კატეგორიული ცვლადის მნიშვნელობები ასეთი სახლებისთვის გამოტოვებულია.
  - 81 (5.55%) nan value გვქონდა კატეგორიულ სვეტებში `GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`. მათი შესაბამისი numerical სვეტებია 
  "GarageYrBlt"(რომელშიც ასევე 81 (5.55%) null value გვქონდა) და კიდევ "GarageCars" (Size of garage in car capacity) და "GarageArea" (Size of garage in square feet), 
  რომლებშიც 81 მნიშვნელობა არის 0-ის ტოლი. სავარაუდოდ ჩვენი მონაცემებიდან 81 სახლს არ ჰქონდა საერთოდ ავტოფარეხი და სწორედ ამიტომ იყო მათი შესაბამისი სვეტების მნიშვნელობები გამოტოვებული.
  - 38 (2.6%) nan value გვქონდა კატეგორიულ სვეტებში `BsmtExposure` და `BsmtFinType2`, ხოლო 37 (2.53%) nan value გვქონდა კატეგორიულ სვეტებში `BsmtQual`, `BsmtCond` და `BsmtFinType1`. 
  ეს სვეტები არის basement-ის შესაბამისი კატეგორიული ცვლადები- მისი ხარისხი, მდგომარეობა და ტიპი. მისი შესაბამისი numerical ცვლადია "TotalBsmtSF"- Total square feet of basement area, 
  რომლის 37 მნიშვნელობა არის 0, რაც იმას ნიშნავს, რომ მის შესაბამის კატეგორიულ სვეტებში გამოტოვებული მონაცემების არსებობა სავარაუდოდ აიხსნება იმით, რომ ამ სახლებს საერთოდ არ აქვთ basement.
  - 1 (0.07%) nan value გვქონდა კატეგორიულ სვეტში `Electrical`, რომელიც არის Electrical system.
  - 259 (17.74%) nan value გვქონდა numerical სვეტში `LotFrontage` (Linear feet of street connected to property).
  - 81 (5.55%) nan value გვქონდა numerical სვეტში `GarageYrBlt`, რაც უკვე აღვნიშნეთ ზემოთ.
  - 8 (0.55%) nan value გვქონდა numerical სვეტში `MasVnrArea` (Masonry veneer area in square feet).
- ამ ახსნებიდან და ანალიზიდან გამომდინარე გავაკეთე შემდეგი:
  - ისეთი სვეტები, სადაც გამოტოვებული მნიშვნელობები იყო 80%-ზე მეტი ამოვაგდე. ასეთი კატეგორიული სვეტები იყო `Alley`, `PoolQC`, `Fence`, `MiscFeature`.
  - `MasVnrType`-ში გამოტოვებული მონაცემები შევავსე "None"-ით, თუ მისი შესაბამისი "MasVnrArea" იყო 0, სხვა შემთხვევაში შევავსე მოდით. 
  - `FireplaceQu`-ში გამოტოვებული მონაცემები შევავსე "None"-ით.
  - garage-თან და basement-თან დაკავშირებულ კატეგორიულ ცვლადებში (`GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`, `BsmtExposure`, `BsmtFinType2`, `BsmtQual`, `BsmtCond`, `BsmtFinType1`) 
  გამოტოვებული მონაცემები შევავსე "None"-ით, რადგან ავტოფარეხი და სარდაფი საერთოდ არ აქვთ ასეთ სახლებს.
  - `Electrical`-ში გამოტოვებული 1 მნიშვნელობა შევავსე მოდით.
  - numerical `LotFrontage`-ში გამოტოვებული მონაცემები შევავსე მედიანით.
  - numerical `MasVnrArea`-ში გამოტოვებული მონაცემები შევავსე 0-ით, თუ მისი შესაბამისი "MasVnrType" იყო "None", სხვა შემთხვევაში შევავსე მედიანით.
  - numerical `GarageYrBlt`-ში გამოტოვებული მონაცემები შევავსე 0-ით, რადგან ასეთ სახლებს ავტოფარეხი არ აქვთ.
- კატეგორიული ცვლადები რიცხვითში გადავიყვანე OneHotEncoding-ით. (WOE არ გამოგვადგებოდა, რადგან რეგრესიის ამოცანა გვაქვს და ბინარული კლასიფიკაციის 
მსგავსად 2 კლასად (დადებითად და უარყოფითად) ვერ გაყოფდა)

## Feature Selection
- აქ გამოვიყენე 3 სხვადასხვა ვარიანტი და შედარებით უკეთესი დავტოვე საბოლოოდ:
  - 1. target ცვლადთან ანუ "SalePrice"-თან კორელაციით გავფილტრე მახასიათებლები. Threshold ავიღე 0.5 და დამრჩა 12 მახასიათებელი. 
  ამ 12 მახასიათებლისთვის ზემოთ აღნიშნული მოდელები დავატრენინგე, გამოვიყენე hyperparameter tuning და ამოვარჩიე საუკეთესო მოდელი (RandomForest)
  საუკეთესო ჰიპერპარამეტრებით და საუკეთესო R2-ით (0.82).
  - 2. აქაც target ცვლადთან ანუ "SalePrice"-თან კორელაციით გავფილტრე მახასიათებლები. ამჯერად Threshold ავიღე 0.6 და დამრჩა 6 მახასიათებელი. 
  ამ 6 მოვიქეცი იგივენაირად. საუკეთესო მოდელი აქაც იყო RandomForest (R2=0.81). შკარად მცირედით, მაგრამ მაინც უარესი შედეგი მოგვცა ყველა მოდელზე, ამიტომ ისევ წინა 
  feature-ები ჯობდა ჯერჯერობით.
  - 3. აქ სანამ RFE-ს გამოვიყენებდი, იქამდე კორელაციის ფილტრი გამოვიყენე (OneHotEncoding-ის შემდეგ 247 სვეტი მქონდა და რომ შემემცირებინა, არასაჭირო ცვლადები რომ გადამეგდო) და 0.4-ზე 
  ნაკლები კორელაციის მქონდე ცვლადები გაიფილტრა, რის შემდეგაც დარჩა 21. ამ 21 მახასიათებლიდან RFE-ით ამოვარჩიე 10. ამ 10 ცვლადისთვის ისევ იგივენაირად შევაფასე მოდელები და ძალიან 
  მცირედით ნაკლები იყო, ვიდრე პირველი. მაინც პირველი ვარიანტი დავტოვე ცვლადების გადარჩევის. (მარტო RFE-ით ვცადე მაქამდე და ბევრად ცუდი შედეგები მომცა, ამიტომ კორელაციის ფილტრი მივაშველე)


## Training
- გამოვიყენე როგორც წრფივი, ისე ხის მოდელები (Linear Regression, Ridge, Lasso, ElasticNet, Decision Tree, Random Forest, XGBoost)
- თითოეული მოდელისთვის მქონდა შესაბამისი ჰიპერპარამეტრების სივრცე და GridSearchCV-ით თითოეული მოდელისთვის ჰიპერპარამეტრების ოპტიმიზაცია 
  მოხდა R2 score-ის მიხედვით (kFoldCrossValidation-ით).
- საუკეთესო მოდელად შევარჩიე Random Forest შემდეგი ჰიპერპარამეტრებით: {'regressor__max_depth': 15, 'regressor__min_samples_leaf': 5, 'regressor__min_samples_split': 2, 'scaler': None}, 
  რადგან საუკეთესო შედეგი ჰქონდა cross ვალიდაციით.
- საბოლოოდ შერჩეული მოდელი თავისი პარამეტრებით და HousePricePreprocessing კლასი გავაერთიანე pipeline-ში.


## MLflow Tracking
- ექსპერიმენტების ბმული: https://dagshub.com/mrekh21/House_Prices.mlflow/#/experiments/0?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D
- ზემოთ უკვე აღწერილია ყველა დალოგვა
- საუკეთესო მოდელის შედეგები (train set-ზე):
  - `train_rmse_log`= 0.11829719568965139
  - `train_mae` = 13799.294243915072
  - `train_rmse` = 23469.573025595124
  - `train_mse` = 550820858.0037423
  - `train_r2_score` = 0.9126622288745652
- kaggle competition-ზე submission-ის score: 0.16288
- რადგან R2 score გვაქვს 0.91, ეს იმას ნიშნავს, რომ მოდელი train set-ზე საკმაოდ კარგ პროგნოზებს აკეთებს, ამიტომ underfitting არ გვაქვს.
- რაც შეეხება overfitting-ს, kaggle log RMSE-ით აფასებს, ამიტომ რადგან train set-ზე log RMSE იყო 0.118.. ხოლო kaggle-ის score-ით test set-ზე
0.162.. მივიღეთ, როგორც ჩანს მოდელი ნანახ მონაცემებზე უკეთესად აკეთებს პროგნოზს, ვიდრე უნახავ მონაცემებზე, თუმცა დიდი gap-ი მაინც არაა, დაახლოებით ერთ რეინჯშია.
