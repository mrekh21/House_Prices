# სახლების ფასების პროგნოზი - House Prices: Advanced Regression Techniques

Kaggle Competition: https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques

## კონკურსის მიმოხილვა:

ეს competition-ი მიზნად ისახავს სახლების საბოლოო ფასის ("SalePrice") პროგნოზირებას 79 მახასიათებლის გამოყენებით. 
კონკურსის მიზანია ისეთი მოდელის შექმნა, რომელიც მაქსიმალურად ზუსტად განსაზღვრავს საცხოვრებელი სახლის ღირებულებას სხვადასხვა პარამეტრის მიხედვით.


## ჩემი მიდგომა პრობლემის გადასაჭრელად

### 1. მონაცემების ანალიზი
- სატრენინგო მონაცემების ანალიზი, არასაჭირო სვეტების ამოგდება
- გამოტოვებული მნიშვნელობების ანალიზი სვეტების მიხედვით
- კატეგორიული ცვლადების გადაყვანა რიცხვითში


### 2. Cleaning & Feature Engineering
- გამოტოვებული მონაცემების შევსება სვეტების ანალიზის შესაბამისად ("None", median, mode, 0)
- არასაჭირო სვეტების ამოგდება ("Id", "Utilities")
- აშკარა Outlier-ების ამოგდება SalePrice-თან მიმართებით ("GrLivArea", "LotArea", "LotFrontage")

### 3. Feature Selection
- 3 სხვადასხვა მეთოდით feature-ების ამორჩევა (სხვადასხვა threshold-ის კორელაციის ფილტრები და RFE)
- თითოეული ამორჩეული ცვლადებისთვის საუკეთესო მოდელების და საუკეთესო ჰიპერპარამეტრების შერჩევა RMSLE-ის მიხედვით (GridSearchCV, KFoldCrossValidation)
- გამოყენებული ალგორითმები (მითითებულია რა პარამეტრებისთვის მქონდა ჰიპერპარამეტრების სივრცე):
  - `LinearRegression`
  - `Ridge` (alpha, solver)
  - `Lasso` (alpha)
  - `ElasticNet` (alpha, l1_ratio)
  - `DecisionTreeRegressor` (max_depth, min_samples_split, min_samples_leaf, max_features)
  - `RandomForestRegressor` (max_depth, min_samples_split, min_samples_leaf, max_features, n_estimators)
  - `XGBoostRegressor` (learning_rate, max_depth, gamma, n_estimators)
- `GridSearchCV`  ჰიპერპარამეტრების tuning-სთვის
- `K-Fold-Cross-Validation` ვალიდაციისთვის
- `MinMaxScaler` და `StandardScaler` მონაცემების სკალირებისთვის

### 4. შეფასების მეტრიკები
- `Mean Absolute Error (MAE)`
- `Mean Squared Error (MSE)`
- `Root Mean Squared Error (RMSE)`
- `R2 Score`
- `Root Mean Squared Log Error (RMSLE)`- Kaggle ამით აფასებს

### 5. Training & Final Pipeline
- Cross ვალიდაციით საუკეთესო შედეგის მქონე მოდელის არჩევა საუკეთესო ჰიპერპარამეტრებით
- მისი შესაბამისი feature-ების ამორჩევა საბოლოო მოდელისთვის
- საბოლოო მოდელისთვის preprocessing კლასის შექმნა
- საბოლოო მოდელისთვის pipeline-ის შექმნა
- საბოლოო მოდელის ტრენინგი და შეფასება სატრენინგო და სატესტო მონაცემებზე

### 5. მოდელის ლოგირება MLflow-ზე
- ექსპერიმენტის დასახელება: `Final_Pipeline`
- Run-ის სახელი: `XGBRegressor_with_preprocessing`
- მოდელის ატვირთვა Model Registry-ში
- Test და Train set-ების შესაბამისი საბოლოო შეფასებების (MAE, MSE, RMSE, R2, RMSLE) ლოგირება
- ჰიპერპარამეტრების ლოგირება

### 6. სატრენინგო მონაცემების ანალიზის ლოგირება MLflow-ზე
- ექსპერიმენტის დასახელება: `Train_Set_Analysis`
- Run-ის სახელი: `Data_Analysis`
- SalePrice ცვლადის განაწილების ატვირთვა Artifacts-ში
- SalePrice-თან შედარებით მაღალკორელირებული (>0.5) numerical სვეტების კორელაციის მატრიცის ატვირთვა Artifacts-ში
- კატეგორიული/რიცხვითი ცვლადების განაწილებების ცხრილების ატვირთვა Artifacts-ში
- კატეგორიული/რიცხვითი სვეტების მიხედვით გამოტოვებული მონაცემების რაოდენობისა და პროცენტულობის ცხრილების ატვირთვა Artifacts-ში

### 7. Feature-ებისა და მათი შესაბამისი მოდელების შერჩევის 3 სხვადასხვა ვარიანტის ლოგირება MLflow-ზე:
- 1. 14 feature-ის გადარჩევა კორელაციის ფილტრით (threshold=0.5)
  - ექსპერიმენტის დასახელება: `Feature_Model_Selection_1`
  - Run-ის სახელი: `Corr_Threshold_0.5`
  - ამორჩეული feature-ების ლოგირება პარამეტრებში
  - ტესტირებული ყველა მოდელისთვის საუკეთესო ჰიპერპარამეტრების ლოგირება პარამეტრებში
  - თითოეული მოდელისთვის cross ვალიდაციის საუკეთესო RMSLE-ების ლოგირება მეტრიკებში
  - ამორჩეული feature-ების  target-თან კორელაციის ვიზუალიზაციის ატვირთვა Artifacts-ში

- 2. 10 feature-ის გადარჩევა კორელაციის ფილტრით (threshold=0.55)
  - ექსპერიმენტის დასახელება: `Feature_Model_Selection_2`
  - Run-ის სახელი: `Corr_Threshold_0.55`
  - ამორჩეული feature-ების ლოგირება პარამეტრებში
  - ტესტირებული ყველა მოდელისთვის საუკეთესო ჰიპერპარამეტრების ლოგირება პარამეტრებში
  - თითოეული მოდელისთვის cross ვალიდაციის საუკეთესო RMSLE-ების ლოგირება მეტრიკებში
  - ამორჩეული feature-ების  target-თან კორელაციის ვიზუალიზაციის ატვირთვა Artifacts-ში

- 3. 10 მახასიათებლის შერჩევა კორელაციის ფილტრის (threshold=0.4) და RFE-ის კომბინაციით
  - ექსპერიმენტის დასახელება: `Feature_Model_Selection_3`
  - Run-ის სახელი: `Corr_Threshold_0.4_with_RFE`
  - ამორჩეული feature-ების ლოგირება პარამეტრებში
  - ტესტირებული ყველა მოდელისთვის საუკეთესო ჰიპერპარამეტრების ლოგირება პარამეტრებში
  - თითოეული მოდელისთვის cross ვალიდაციის საუკეთესო RMSLE-ების ლოგირება მეტრიკებში
  - კორელაციის ფილტრით ამორჩეული feature-ების target-თან კორელაციის ვიზუალიზაციის ატვირთვა Artifacts-ში
  - RFE-თ ამორჩეული feature-ების  ვიზუალიზაციის ატვირთვა Artifacts-ში
  - RFE-თ ამორჩეული feature-ების target-თან კორელაციის ვიზუალიზაციის ატვირთვა Artifacts-ში
    

## რეპოზიტორიის სტრუქტურა
- `model_experiment.ipynb`: სატრენინგო მონაცემების ანალიზი, Cleaning, Feature Engineering, Feature Selection, Training, 
საბოლოო pipeline თავისი preprocessing კლასით და MLflow-ზე დალოგვები.
- `model_inference.ipynb`: მოდელის და-load-ება Model Registry-დან, test.csv-ზე პროგნოზი და prediction-ების csv ფაილად შენახვა submission-სთვის.
- `README.md`: ახლა რასაც კითხულობთ, ეგ.

## Train Set Analysis
#### გამოტოვებული მნიშვნელობების ანალიზი: 
- 1453 (99.52%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ `PoolQC`-ში, რაც არის აუზის ხარისხი. თუ ვნახავთ მის შესაბამის numerical სვეტს, 
  "PoolArea", რომელიც არის აუზის ფართობი, მისი 1453 მნიშვნელობა არის 0, რაც იმას ნიშნავს, რომ სახლების უმეტესობას აუზი არ აქვს, 
  შესაბამისად "PoolQC" ანუ აუზის ხარისხის კატეგორიული მნიშვნელობები გამოტოვებულია.
- 1406 (96.3%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ სვეტში `MiscFeature` რომელიც არის Miscellaneous feature not covered in other categories, 
  რომლის შესაბამისი numerical ცვლადის "MiscVal"-ის ანუ $Value of miscellaneous feature-ის 1400-ზე მეტი მნიშვნელობა ასევე არის 0, რაც იმას ნიშნავს, 
  რომ ეს მახასიათებელი სახლების უმეტესობას არ გააჩნია.
- 1369 (93.77%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ სვეტში `Alley`, რაც არის Type of alley access, რაც სავარაუდოდ სახლების უმეტესობას არ აქვს.
- 1179 (80.75%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ სვეტში `Fence`, რომელიც არის ღობის ხარისხი, ამიტომ ამდენი გამოტოვებული მონაცემის არსებობა სავარაუდოდ 
  ნიშნავს, რომ სახლების უმეტესობას ღობე საერთოდ არ აქვს.
- 872 (59.73%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ სვეტში `MasVnrType`, რომელიც არის Masonry veneer type, რომლის შესაბამისი numerical სვეტია "MasVnrArea", 
  რომლის 800-ზე მეტი მნიშვნელობა არის 0, რაც იმას ნიშნავს, რომ სახლების ნახევარზე მეტს Masonry veneer საერთოდ არ გააჩნია, შესაბამისად მისი ტიპის აღმნიშვნელი 
  კატეგორიული ცვლადის მნიშვნელობები გამოტოვებულია.
- 690 (47.26%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ სვეტში `FireplaceQu`, რომელიც არის Fireplace quality. მისი შესაბამისი numerical ცვლადია "Fireplaces" 
  ანუ Number of fireplaces, რომლის 690 მნიშვნელობა არის 0, რაც იმას ნიშნავს, რომ სახლების ამ რაოდენობას არ გააჩნია ბუხრები, შესაბამისად მისი ხარისხის აღმნიშვნელი 
  კატეგორიული ცვლადის მნიშვნელობები ასეთი სახლებისთვის გამოტოვებულია.
- 81 (5.55%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ სვეტებში `GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`. მათი შესაბამისი numerical სვეტებია 
  "GarageYrBlt"(რომელშიც ასევე 81 (5.55%) null value გვქონდა) და კიდევ "GarageCars" (Size of garage in car capacity) და "GarageArea" (Size of garage in square feet), 
  რომლებშიც 81 მნიშვნელობა არის 0-ის ტოლი. სავარაუდოდ ჩვენი მონაცემებიდან 81 სახლს არ ჰქონდა საერთოდ ავტოფარეხი და სწორედ ამიტომ იყო მათი შესაბამისი სვეტების მნიშვნელობები გამოტოვებული.
- 38 (2.6%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ სვეტებში `BsmtExposure` და `BsmtFinType2`, ხოლო 37 (2.53%) nan value გვქონდა კატეგორიულ სვეტებში `BsmtQual`, `BsmtCond` და `BsmtFinType1`. 
  ეს სვეტები არის basement-ის შესაბამისი კატეგორიული ცვლადები- მისი ხარისხი, მდგომარეობა და ტიპი. მისი შესაბამისი numerical ცვლადია "TotalBsmtSF"- Total square feet of basement area, 
  რომლის 37 მნიშვნელობა არის 0, რაც იმას ნიშნავს, რომ მის შესაბამის კატეგორიულ სვეტებში გამოტოვებული მონაცემების არსებობა სავარაუდოდ აიხსნება იმით, რომ ამ სახლებს საერთოდ არ აქვთ basement.
- 1 (0.07%) გამოტოვებული მნიშვნელობა გვქონდა კატეგორიულ სვეტში `Electrical`, რომელიც არის Electrical system.
- 259 (17.74%) გამოტოვებული მნიშვნელობა გვქონდა numerical სვეტში `LotFrontage` (Linear feet of street connected to property).
- 81 (5.55%) გამოტოვებული მნიშვნელობა გვქონდა numerical სვეტში `GarageYrBlt`, რაც უკვე აღვნიშნეთ ზემოთ.
- 8 (0.55%) გამოტოვებული მნიშვნელობა გვქონდა numerical სვეტში `MasVnrArea` (Masonry veneer area in square feet).
 
    
## Cleaning & Feature Engineering
- "None"-ით შევავსე ისეთი კატეგორიული სვეტები, რომლებშიც ინფორმაცია გამოტოვებული იყო იყო ავტოფარეხის მდგომარეობის/ტიპის, სარდაფის ტიპის და სხვა ისეთი მახასიათებლის შესახებ, რომელიც ასეთ სახლებს არ გააჩნიათ.
ასეთი სვეტები იყო: `Alley`, `PoolQC`, `Fence`, `MiscFeature`, `GarageType`, `GarageFinish`, `GarageQual`, `GarageCond`, `BsmtExposure`, `BsmtFinType2`, `BsmtQual`, `BsmtCond`, `BsmtFinType1`, `FireplaceQu`.
- `Electrical`-ში გამოტოვებული 1 მნიშვნელობა შევავსე მოდით.
- numerical `LotFrontage`-ში გამოტოვებული მონაცემები შევავსე მედიანით 'Neighbourhood'-ის მიხედვით (groupby).
- numerical `MasVnrArea`-ში გამოტოვებული მონაცემები შევავსე 0-ით, თუ მისი შესაბამისი "MasVnrType" იყო "None", სხვა შემთხვევაში შევავსე მედიანით.
- numerical `GarageYrBlt`-ში გამოტოვებული მონაცემები შევავსე 0-ით, რადგან ასეთ სახლებს ავტოფარეხი არ აქვთ.
- ამოვაგდე `Utilities` სვეტი, რადგან მხოლოდ ერთი მნიშვნელობა ჰქონდა და არანაირ ინფორმაციას არ გვაწვდიდა.
- შევქმენი შემდეგი დამატებითი feature-ები: `TotalSF`, `TotalBath`, `HasPool`, `HasGarage`, `HasBasement`, `HasFireplace`, `PorchArea`, `HasPorch`. (სხვადასხვა Area-ს შესაბამისი სვეტების დაჯამებით ან Area > 0)
- outlier-ები მოვაშორე სვეტებში `GrLivArea`, `LotArea`, `LotFrontage`. ისეთი მონაცემები, სადაც GrLivArea (ფართობი) იყო 4000-ზე მეტი, ხოლო სახლის ფასი 300000-ზე ნაკლები, აშკარად გამოცალკევებული იყო სხვა მონაცემებისგან
და აშკარად outlier-ები იყო. LotArea-ს მნიშვნელობა 100000-ზე მეტი იყო აშკარა outlier SalePrice-თან მიმართებით, ისევე როგორც LotFrontage-ის მნიშვნელობა 200-ზე მეტი. (scatter plot-ით ვნახე ამ სვეტების target-თან დამოკიდებულება და აშკარა outlier-ები ესენი იყო)
- კატეგორიული ცვლადები რიცხვითში გადავიყვანე OneHotEncoding-ით.


## Feature Selection
- აქ გამოვიყენე 3 სხვადასხვა ვარიანტი და შედარებით უკეთესი დავტოვე საბოლოოდ (ის რომელსაც ყველაზე კარგი შედეგი ჰქონდა cross ვალიდაციით და ყველაზე ნაკლებად იყო overfit-ში):
  - 1. target ცვლადთან ანუ "SalePrice"-თან კორელაციით გავფილტრე მახასიათებლები. Threshold ავიღე 0.5 და დამრჩა 14 მახასიათებელი. 
  ამ 14 მახასიათებლისთვის ზემოთ აღნიშნული მოდელები დავატრენინგე (GridSearchCV, KFoldCrossValidation) და ამოვარჩიე საუკეთესო მოდელი (XGBoost) საუკეთესო ჰიპერპარამეტრებით და საუკეთესო RMSLE-თ (0.1402).
  - 2. აქაც target ცვლადთან ანუ "SalePrice"-თან კორელაციით გავფილტრე მახასიათებლები. ამჯერად Threshold ავიღე 0.55 და დამრჩა 10 მახასიათებელი. 
  ამ 10-სთვის მოვიქეცი იგივენაირად. საუკეთესო მოდელი აქაც იყო XGBoost (RMSLE=0.1503). შკარად მცირედით, მაგრამ მაინც უარესი შედეგი მოგვცა ყველა მოდელზე, ამიტომ ისევ წინა 
  feature-ები ჯობდა ჯერჯერობით.
  - 3. აქ სანამ RFE-ს გამოვიყენებდი, იქამდე კორელაციის ფილტრი გამოვიყენე (OneHotEncoding-ის შემდეგ 264 სვეტი მქონდა და რომ შემემცირებინა, ნაკლებად კორელირებული ცვლადები რომ გადამეგდო), რის შემდეგაც დარჩა 24.
  ამ მახასიათებლებიდან RFE-ით ამოვარჩიე 10. ამ 10 ცვლადისთვის ისევ იგივენაირად შევაფასე მოდელები და აქაც უფრო ცუდი შედეგი მივიღე ვიდრე პირველში, ამიტომ მაინც პირველი ვარიანტი დავტოვე ცვლადების გადარჩევის.
(მარტო RFE-ით ვცადე მაქამდე და ბევრად ცუდი შედეგები მომცა, ამიტომ კორელაციის ფილტრი მივაშველე, ასევე 15 ცვლადის ამორჩევისას მაინც ცუდი შედეგები ჰქონდა და ამიტომ ბოლოს 10 ამოვარჩევინე)


## Training
- თითოეული feature selection ვარიანტისთვის GridSearchCV-ს გადავცემდი მოდელებს (თითოეულისთვის მითითებული მქონდა შესაბამისი ჰიპერპარამეტრების სივრცე და სკალერი). KFoldCrossvalidation-ით მიღებული RMSLE-ით ავარჩიე
საბოლოო მოდელი და პარამეტრების შერჩევის მეთოდი.
- საუკეთესო მოდელი იყო XGBRegressor შემდეგი ჰიპერპარამეტრებით: Best parameters = {'regressor__gamma': 0, 'regressor__learning_rate': 0.05, 'regressor__max_depth': 3, 'regressor__n_estimators': 200, 'scaler': StandardScaler()}
- საბოლოოდ შერჩეული მოდელი თავისი ჰიპერპარამეტრებით, სკალერი და HousePricePreprocessing კლასი გავაერთიანე pipeline-ში.
- outlier-ების მოშორება გავიტანე ცალკე ფუნქციად, რომელსაც ვიძახებ მხოლოდ სატრენინგო მონაცემებზე, სანამ fit-ს გავაკეთებ.


## MLflow Tracking
- ექსპერიმენტების ბმული: https://dagshub.com/mrekh21/House_Prices.mlflow/#/experiments/0?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D
- ზემოთ უკვე აღწერილია ყველა დალოგვა
- საუკეთესო მოდელის შედეგები:
  
- train_RMSE: 17681.71
- train_MAE : 12913.90
- train_MSE : 312642746.58
- train_R2 : 0.9522
- train_RMSLE  : 0.1092

- test_RMSE: 28579.84
- test_RAE: 18712.82
- test_MSE: 816807280.87
- test_R2: 0.8935
- test_RMSLE: 0.1548

- kaggle competition-ზე submission-ის score: 0.15814 (ახლოსაა ჩემს test_RMSLE= 0.1548 -სთან)
- რადგან R2 score გვაქვს 0.9522 სატრენინგო მონაცემებზე, ეს იმას ნიშნავს, რომ მოდელი train set-ზე საკმაოდ კარგ პროგნოზებს აკეთებს, ამიტომ underfitting არ გვაქვს.
- რაც შეეხება overfitting-ს, test set-ზე R2 score არის 0.8935, რაც იმას ნიშნავს, რომ სატესტო მონაცემების დაახლ. 90%-ს სწორად აფასებს, თუმცა ეს ნაკლებია ვიდრე სატრენინგო მონაცემების შედეგი.  
როგორც ჩანს მოდელი ნანახ მონაცემებზე უკეთესად აკეთებს პროგნოზს, ვიდრე უნახავ მონაცემებზე, თუმცა ცუდი შედეგი არ აქვს ცალკე სატესტო რომ შევაფასოდ. 0.05 არის RMSLE-ებს შორის სხვაობა.
(ყველაზე ნაკლებად overfit-ში წასული მოდელია იმათთან შედარებით, რაც მანამდე სხვა feature engineering-ით და feature selection-ით ვცადე. სხვა პარამეტრების მითითებაც ვცადე min_child_weight, subsample და ა.შ
მაგრამ დიდად ვერ გააუმჯობესა შედეგი და სავარაუდოდ ძაან პატარა დატის ბრალია ეს overfit)
